---
title: "API 调用问题"
description: "API调用常见问题解答"
---

### 如何调用我们的API?

您可以参考我们平台提供的 [接口文档](https://open.bigmodel.cn/dev/api) 进行调用。

### 同步、异步、SSE调用方式有什么区别？

同步、异步、SSE调用是三种不同的 API 响应方式。

- **SSE调用**：客户发起请求后，可以流式的实时获取到模型生成的内容直到推理结束，类似于智谱清言APP上的打字机效果。该调用方式适用于对首响及响应时长要求较高的场景，如和用户直接进行交互的智能客服、对话闲聊等。我们推荐您使用SSE调用，用户体验更好。
- **同步调用**：客户发起请求，模型完成推理后一次性返回全量生成结果。
- **异步调用**：客户发起请求后，需要用户调用异步接口结果查询模型处理状态和推理结果，如处理完成，可通过结果查询接口获取到模型生成结果。该调用方式适用于对响应时间不敏感的业务场景，如批量处理数据、批量生成文章等。

### 调用模型时的并发限制是多少？

您可以参考 [速率限制](https://open.bigmodel.cn/dev/howuse/rate-limits) 了解当前的并发以及如何提升您的并发数。

### temperature 和top_p参数该如何设置？

在大语言模型中，temperature 和 top_p 参数用于调节生成文本的多样性和质量。

- **temperature** 参数用于控制模型输出结果的随机性，取值范围是: [0.0,1.0]。值越大，生成的文本越随机，值越小，生成的文本越稳定；
- **top_p** 参数用于控制模型输出结果中单词或词组的概率分布，取值范围是：[0.0,1.0]。值越大，模型会在更多单词或词组中进行选择，增加输出结果的随机性，值越小，模型会在更少的单词或词组中进行选择，增加输出结果的稳定性。

要获得更有创意、更多样性的回答，可将 temperature 设为较高值或 top_p 设为较高值；要获得更稳定、更有确定性的回答，可将 temperature 设为较低值或 top_p 设为较低值。您可根据实际的应用场景调整temperature 或 top_p参数，但不要同时调整这两个参数。

### 如何使用函数调用能力？

您可参考 [ 函数调用使用文档](https://open.bigmodel.cn/dev/howuse/functioncall) 了解调用逻辑。

### tools列表支持传多个函数吗？

tools支持传多个函数，但每次调用只能命中一个。

### 函数调用，知识库检索，网络搜索可以全部添加到tools参数里吗？

函数调用、知识库检索、网络搜索，3个功能互斥。如果同时使用，按照优先级只会生效一个。优先级顺序为：函数调用\>知识库检索\>网络搜索。

### 模型微调怎么做？

目前可通过提交 [模型微调接口文档](https://open.bigmodel.cn/tokenspropay?productIds=product-001) 开发者 Pro 版平台服务权益申请 获得 GLM-4-Flash 模型微调权限，其他模型的微调能力会陆续迭代。开通权限后可通过模型微调接口文档了解调用详情。

您也可以购买我们的云端私有化服务，获得私有化部署及模型微调服务，请随时 [ 联系我们](https://open.bigmodel.cn/online-book/modelLocalDeployment?channel_track_key=modelLocalDeployment)，我们的咨询顾问将为您详细介绍。