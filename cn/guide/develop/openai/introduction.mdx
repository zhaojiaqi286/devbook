---
title: "OpenAI SDK 兼容"
description: "使用 OpenAI SDK 调用智谱AI模型"
---

<Info>
智谱AI 完全兼容 OpenAI SDK，您可以使用熟悉的 OpenAI SDK 来调用智谱AI的各种模型，无需学习新的API接口。
</Info>

## 什么是 OpenAI SDK 兼容

智谱AI提供与OpenAI API完全兼容的接口，这意味着您可以使用现有的OpenAI SDK代码，只需要简单修改API密钥和基础URL，就能无缝切换到智谱AI的模型服务。这种兼容性让您能够：

- 快速迁移现有的OpenAI应用
- 使用熟悉的开发模式和工具
- 享受智谱AI模型的强大能力
- 保持代码的一致性和可维护性

### 核心优势

<CardGroup cols={2}>
  <Card title="零学习成本" icon="graduation-cap">
    如果您已经熟悉OpenAI SDK，可以立即上手使用
  </Card>
  <Card title="快速迁移" icon="arrows-rotate">
    现有OpenAI应用可以快速迁移到智谱AI平台
  </Card>
  <Card title="生态兼容" icon="puzzle-piece">
    兼容OpenAI生态系统中的各种工具和框架
  </Card>
  <Card title="持续更新" icon="arrow-up">
    跟随OpenAI SDK更新，保持最新功能支持
  </Card>
</CardGroup>

## 环境要求

<mcreference link="https://bigmodel.cn/dev/api/thirdparty-frame/openai-sdk" index="2">2</mcreference>

<CardGroup cols={2}>
  <Card title="Python 版本" icon="python">
    Python 3.7.1 或更高版本
  </Card>
  <Card title="OpenAI SDK" icon="package">
    OpenAI SDK 版本不低于 1.0.0
  </Card>
</CardGroup>

<Warning>
请确保使用 OpenAI SDK 1.0.0 或更高版本，旧版本可能存在兼容性问题。
</Warning>

## 安装 OpenAI SDK

### 使用 pip 安装

```bash
# 安装或升级到最新版本
pip install --upgrade 'openai>=1.0'

# 验证安装
python -c "import openai; print(openai.__version__)"
```

### 使用 poetry 安装

```bash
poetry add "openai>=1.0"
```

## 快速开始

### 获取 API Key

1. 访问 [智谱AI开放平台](https://bigmodel.cn)
2. 注册并登录您的账户
3. 在控制台中创建 API Key
4. 复制您的 API Key 以供使用

<Tip>
建议将 API Key 设置为环境变量：`export ZHIPUAI_API_KEY=your-api-key`
</Tip>

### 创建客户端

<Tabs>
  <Tab title="基础配置">
    
```python
from openai import OpenAI

# 创建智谱AI客户端
client = OpenAI(
    api_key="your-zhipuai-api-key",
    base_url="https://open.bigmodel.cn/api/paas/v4/"
)
```

  </Tab>
  <Tab title="环境变量">
    
```python
from openai import OpenAI
import os

# 使用环境变量
client = OpenAI(
    api_key=os.getenv("ZHIPUAI_API_KEY"),
    base_url="https://open.bigmodel.cn/api/paas/v4/"
)
```

  </Tab>
  <Tab title="配置类">
    
```python
from openai import OpenAI
from dataclasses import dataclass

@dataclass
class ZhipuAIConfig:
    api_key: str
    base_url: str = "https://open.bigmodel.cn/api/paas/v4/"
    timeout: int = 30
    max_retries: int = 3

config = ZhipuAIConfig(api_key="your-api-key")
client = OpenAI(
    api_key=config.api_key,
    base_url=config.base_url,
    timeout=config.timeout,
    max_retries=config.max_retries
)
```

  </Tab>
</Tabs>

## 基础使用示例

### 简单对话

<mcreference link="https://bigmodel.cn/dev/api/thirdparty-frame/openai-sdk" index="2">2</mcreference>

```python
from openai import OpenAI

client = OpenAI(
    api_key="your-zhipuai-api-key",
    base_url="https://open.bigmodel.cn/api/paas/v4/"
)

completion = client.chat.completions.create(
    model="glm-4-air-250414",
    messages=[
        {"role": "system", "content": "你是一个聪明且富有创造力的小说作家"},
        {"role": "user", "content": "请你作为童话故事大王，写一篇短篇童话故事"}
    ],
    top_p=0.7,
    temperature=0.9
)

print(completion.choices[0].message.content)
```

### 流式响应

```python
stream = client.chat.completions.create(
    model="glm-4-air-250414",
    messages=[
        {"role": "user", "content": "写一首关于人工智能的诗"}
    ],
    stream=True,
    temperature=0.8
)

for chunk in stream:
    if chunk.choices[0].delta.content is not None:
        print(chunk.choices[0].delta.content, end="", flush=True)

print()  # 换行
```

### 多轮对话

```python
class ChatBot:
    def __init__(self, api_key: str):
        self.client = OpenAI(
            api_key=api_key,
            base_url="https://open.bigmodel.cn/api/paas/v4/"
        )
        self.conversation = [
            {"role": "system", "content": "你是一个有用的AI助手"}
        ]
    
    def chat(self, user_input: str) -> str:
        # 添加用户消息
        self.conversation.append({"role": "user", "content": user_input})
        
        # 调用API
        response = self.client.chat.completions.create(
            model="glm-4-air-250414",
            messages=self.conversation,
            temperature=0.7
        )
        
        # 获取AI回复
        ai_response = response.choices[0].message.content
        
        # 添加到对话历史
        self.conversation.append({"role": "assistant", "content": ai_response})
        
        return ai_response
    
    def clear_history(self):
        """清除对话历史，保留系统提示"""
        self.conversation = self.conversation[:1]

# 使用示例
bot = ChatBot("your-api-key")
print(bot.chat("你好，请介绍一下自己"))
print(bot.chat("你能帮我写代码吗？"))
print(bot.chat("写一个Python的快速排序算法"))
```

## 支持的模型

### 语言模型

| 模型名称 | 描述 | 适用场景 |
|----------|------|----------|
| glm-4-plus | 最强大的语言模型 | 复杂推理、创作、专业问答 |
| glm-4-air-250414 | 平衡性能和成本 | 通用对话、内容生成 |
| glm-4-flash | 快速响应模型 | 实时对话、简单问答 |
| glm-4-long | 长上下文模型 | 长文档处理、深度分析 |

### 多模态模型

| 模型名称 | 描述 | 适用场景 |
|----------|------|----------|
| glm-4v-plus | 强大的视觉理解 | 图像分析、视觉问答 |
| glm-4v | 通用视觉模型 | 图像描述、OCR |

## 高级功能

### 函数调用 (Function Calling)

```python
import json

def get_weather(location: str) -> str:
    """获取指定地点的天气信息"""
    # 这里应该调用真实的天气API
    return f"{location}的天气：晴天，温度25°C"

# 定义函数描述
tools = [
    {
        "type": "function",
        "function": {
            "name": "get_weather",
            "description": "获取指定地点的天气信息",
            "parameters": {
                "type": "object",
                "properties": {
                    "location": {
                        "type": "string",
                        "description": "地点名称，例如：北京、上海"
                    }
                },
                "required": ["location"]
            }
        }
    }
]

# 调用带函数的对话
response = client.chat.completions.create(
    model="glm-4-air-250414",
    messages=[
        {"role": "user", "content": "北京今天天气怎么样？"}
    ],
    tools=tools,
    tool_choice="auto"
)

# 处理函数调用
message = response.choices[0].message
if message.tool_calls:
    for tool_call in message.tool_calls:
        if tool_call.function.name == "get_weather":
            args = json.loads(tool_call.function.arguments)
            result = get_weather(args["location"])
            print(f"函数调用结果: {result}")
```

### 图像理解

```python
import base64
from PIL import Image
import io

def encode_image(image_path: str) -> str:
    """将图像编码为base64字符串"""
    with open(image_path, "rb") as image_file:
        return base64.b64encode(image_file.read()).decode('utf-8')

# 图像理解示例
image_base64 = encode_image("path/to/your/image.jpg")

response = client.chat.completions.create(
    model="glm-4v",
    messages=[
        {
            "role": "user",
            "content": [
                {
                    "type": "text",
                    "text": "请描述这张图片的内容"
                },
                {
                    "type": "image_url",
                    "image_url": {
                        "url": f"data:image/jpeg;base64,{image_base64}"
                    }
                }
            ]
        }
    ],
    temperature=0.7
)

print(response.choices[0].message.content)
```

### 异步调用

```python
import asyncio
from openai import AsyncOpenAI

async def async_chat_example():
    client = AsyncOpenAI(
        api_key="your-zhipuai-api-key",
        base_url="https://open.bigmodel.cn/api/paas/v4/"
    )
    
    response = await client.chat.completions.create(
        model="glm-4-air-250414",
        messages=[
            {"role": "user", "content": "你好，请介绍一下人工智能"}
        ]
    )
    
    return response.choices[0].message.content

# 运行异步函数
result = asyncio.run(async_chat_example())
print(result)
```

## 参数配置

### 常用参数说明

| 参数 | 类型 | 默认值 | 说明 |
|------|------|--------|------|
| model | string | 必填 | 要使用的模型名称 |
| messages | array | 必填 | 对话消息列表 |
| temperature | float | 0.95 | 控制输出的随机性 (0-1) |
| top_p | float | 0.7 | 核采样参数 (0-1) |
| max_tokens | integer | - | 最大输出token数 |
| stream | boolean | false | 是否使用流式输出 |
| stop | string/array | - | 停止生成的标记 |

<Note>
注意：temperature 参数的区间为 (0,1)，do_sample = False (temperature = 0) 在 OpenAI 调用中并不适用。
</Note>

### 参数优化建议

<CardGroup cols={2}>
  <Card title="创意任务" icon="lightbulb">
    - temperature: 0.8-0.9
    - top_p: 0.8-0.9
    - 适用于创作、头脑风暴
  </Card>
  <Card title="分析任务" icon="chart-line">
    - temperature: 0.1-0.3
    - top_p: 0.1-0.3
    - 适用于分析、总结、翻译
  </Card>
  <Card title="对话任务" icon="comments">
    - temperature: 0.7
    - top_p: 0.7
    - 适用于日常对话、问答
  </Card>
  <Card title="代码生成" icon="code">
    - temperature: 0.2
    - top_p: 0.1
    - 适用于代码生成、调试
  </Card>
</CardGroup>

## 错误处理

### 常见错误处理

```python
from openai import OpenAI
from openai import OpenAIError, RateLimitError, APIError
import time
import random

def chat_with_retry(client: OpenAI, messages: list, max_retries: int = 3):
    """带重试机制的聊天函数"""
    for attempt in range(max_retries):
        try:
            response = client.chat.completions.create(
                model="glm-4-air-250414",
                messages=messages,
                timeout=30
            )
            return response.choices[0].message.content
            
        except RateLimitError:
            if attempt < max_retries - 1:
                # 指数退避
                wait_time = (2 ** attempt) + random.uniform(0, 1)
                print(f"请求频率限制，等待 {wait_time:.2f} 秒后重试...")
                time.sleep(wait_time)
            else:
                raise
                
        except APIError as e:
            print(f"API错误: {e}")
            if attempt < max_retries - 1:
                time.sleep(1)
            else:
                raise
                
        except OpenAIError as e:
            print(f"OpenAI错误: {e}")
            raise
            
        except Exception as e:
            print(f"未知错误: {e}")
            raise

# 使用示例
client = OpenAI(
    api_key="your-api-key",
    base_url="https://open.bigmodel.cn/api/paas/v4/"
)

messages = [{"role": "user", "content": "你好"}]
result = chat_with_retry(client, messages)
print(result)
```

## 最佳实践

<CardGroup cols={2}>
  <Card title="性能优化" icon="gauge-high">
    - 使用连接池和会话复用
    - 合理设置超时时间
    - 实施异步调用处理高并发
    - 缓存常用的响应结果
  </Card>
  <Card title="成本控制" icon="dollar-sign">
    - 合理设置max_tokens限制
    - 使用合适的模型（不要过度使用强模型）
    - 实施请求去重机制
    - 监控API使用量
  </Card>
  <Card title="安全性" icon="shield">
    - 使用环境变量存储API密钥
    - 实施输入验证和过滤
    - 记录和监控API调用
    - 定期轮换API密钥
  </Card>
  <Card title="可靠性" icon="shield-check">
    - 实施重试机制和错误处理
    - 设置合理的超时时间
    - 监控API状态和响应时间
    - 准备降级方案
  </Card>
</CardGroup>

## 迁移指南

### 从 OpenAI 迁移

如果您已经在使用 OpenAI API，迁移到智谱AI非常简单：

```python
# 原来的 OpenAI 代码
from openai import OpenAI

client = OpenAI(
    api_key="sk-...",  # OpenAI API Key
    # base_url 使用默认值
)

# 迁移到智谱AI，只需要修改两个地方
client = OpenAI(
    api_key="your-zhipuai-api-key",  # 替换为智谱AI API Key
    base_url="https://open.bigmodel.cn/api/paas/v4/"  # 添加智谱AI base_url
)

# 其他代码保持不变
response = client.chat.completions.create(
    model="glm-4-air-250414",  # 使用智谱AI模型
    messages=[{"role": "user", "content": "Hello!"}]
)
```

### 模型映射

| OpenAI 模型 | 智谱AI 对应模型 | 说明 |
|-------------|----------------|------|
| gpt-4 | glm-4-plus | 最强性能模型 |
| gpt-4-turbo | glm-4-air-250414 | 平衡性能和成本 |
| gpt-3.5-turbo | glm-4-flash | 快速响应模型 |
| gpt-4-vision | glm-4v-plus | 视觉理解模型 |

## 获取帮助

<CardGroup cols={2}>
  <Card title="API 文档" icon="book" href="/api-reference">
    查看完整的API接口文档
  </Card>
  <Card title="OpenAI 官方文档" icon="external-link" href="https://platform.openai.com/docs">
    参考OpenAI官方文档了解更多用法
  </Card>
</CardGroup>

<Note>
智谱AI致力于保持与OpenAI API的完全兼容性，如果您在迁移过程中遇到任何问题，请联系我们的技术支持团队。
</Note>